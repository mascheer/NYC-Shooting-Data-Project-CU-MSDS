---
title: "NYC Shooting Data Report"
author: "Mason Scheer"
date: "2024-11-04"
output:
  pdf_document: default
  html_document: default
---


The data for this report is NYPD data listing every shooting incident that occurred in NYC going back to 2006 through the end of the previous calendar year.

As summarized on the catalog.data.gov, "This data is manually extracted every quarter and reviewed by the Office of Management Analysis and Planning before being posted on the NYPD website. Each record represents a shooting incident in NYC and includes information about the event, the location and time of occurrence. In addition, information related to suspect and victim demographics is also included. This data can be used by the public to explore the nature of shooting/criminal activity."

```{r setup}
#When exploring what kind of analysis I wanted to do, these are the libraries I imported. Not all ended up being utilized in my final version.
library(tidyverse)
library(readr)
library(dplyr)
library(ggplot2)
library(hms)
library(lubridate)
library(ggmap)
library(maps)
```

## Loading the Data

To start the process, I loaded the CSV into R via the linked address to the data on the City of New York website.

```{r load data }
#load the CSV file
original_data <- read_csv(
  "https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD")

#Take a look at the first few lines of data
head(original_data)
```
## Cleaning the Data

After loading the NYC Shooting Data, I explored what the data looked like. I wanted to drop columns I knew I wouldn't be using for my exploration and analysis. I also needed to clean up the date and time fields available as they were initially just character types. I ended up creating one datetime field and dropping the individual date and time columns. The last piece of clean up I did to begin my analysis was factoring the Boroughs field.  

```{r clean data}
#This chunk will be used to clean up the data 
#First, I want to drop columns that I won't be using
cleaned_data <- original_data %>%
  select(-c("LOC_OF_OCCUR_DESC", "LOC_CLASSFCTN_DESC", "LOCATION_DESC", 
            "PRECINCT", "JURISDICTION_CODE", "X_COORD_CD", "Y_COORD_CD",
            "Lon_Lat")) %>%
  mutate(
    OCCUR_DATE = as.Date(OCCUR_DATE, format = "%m/%d/%Y"),
    OCCUR_TIME = hms::as_hms(OCCUR_TIME),
    OCCUR_DATETIME = as.POSIXct(paste(OCCUR_DATE, OCCUR_TIME), 
                                format = "%Y-%m-%d %H:%M:%S"),
    BORO = factor(BORO, levels = c("MANHATTAN", "BRONX", "BROOKLYN", "QUEENS",
                                   "STATEN ISLAND"))
  ) %>%
  select(-c("OCCUR_DATE", "OCCUR_TIME")) %>%
  relocate(OCCUR_DATETIME, .after = 1)
```

## Shooting Summary By Neighborhood

With my data clean, the first visual I wanted to see in my analysis was a summary of shootings by neighborhood. First I grouped the boro field in the data to summarize, and then created a bar chart to create an easy way to see how the neighborhoods in this dataset compare to each other as far as shootings go. I am generally unfamiliar with NYC, so I relied on both research and testimonials from friends who live there to make sense of the summary. I was most interested in the low of Staten Island and high of Brooklyn. Per my research on Staten Island, it is considered one of the safer neighborhoods of the NYC area.  My sister lives in Brooklyn, which has the highest shooting count. While she lives in a safe pocket of Brooklyn, she agreed that this data makes sense after exploring most of the region. She specified that Brooklyn "gets a lot sketchier" the further east you go away from her home in Williamsburg. 

In my exploration of this data, I used the latitude and longitude points for each shooting and integrated them with the Google maps API to plot each point on the graph and show the density of areas with high shootings. I chose not to include this visual due to the inability to interactively zoom into more specific areas without creating either a Shiny app or webpage using javascript/html. The bar chart was sufficient to portray the information the map would have been able to at a zoomed out view of the region. In a future enhancement of this project, I would love to create a Shiny App version of this analysis.

```{r summary by boro}
#creating a variable that explores the shootings summary by neighborhood in NY
summary_by_hood <- cleaned_data %>%
  group_by(BORO)%>%
  summarise(Count = n())


# Create bar plot for summary by neighborhood.
ggplot(summary_by_hood, aes(x = BORO, y = Count, fill = BORO)) +
  geom_bar(stat = "identity") +
  labs(title = "Shooting Incidents by Borough", x = "Borough", 
       y = "Number of Incidents") +
  theme_minimal()
```

## Shooting Incidents Over Time

Another visual I wanted to create using this data was a line graph showing shooting frequencies over time. I was interested to see if there would be any sort of general trend that would indicate specific time periods where shootings were more common. The X axis is set in a series of every six months and the Y axis is the number of shootings per day. As you can see, this creates a dense line, however it still allows us to guage significant times where there were highs and lows. This graph shows us that since 2006, shooting incidents per day have been pretty steady. From around 2012-2019, there appeared to even be a slight decline in daily incidents. Then, as you will see, there is one major interesting point right around Summer 2020 where shooting incidents skyrocket. My immediate hypothesis for this sharp rise was the BLM movement that was prominent in NYC and other major cities across the US. After doing some research, the timeline of the movement would line up with this rise. However to confirm causation rather than just correlating it, I would want to find ways to bring in additional data around the movement such as specific rallies and any acts of violence that occurred directly during them. 

```{r shootings trend over time}
# Extract date from OCCUR_DATETIME
cleaned_data$Date <- as.Date(cleaned_data$OCCUR_DATETIME)

# Count incidents by date
daily_counts <- cleaned_data %>%
  group_by(Date) %>%
  summarise(Incident_Count = n())

# Create time series plot
ggplot(daily_counts, aes(x = Date, y = Incident_Count)) +
  geom_line(color = "blue") +
  labs(title = "Trend of Shooting Incidents Over Time", x = "Date", 
       y = "Number of Incidents") +
  scale_x_date(date_breaks = "6 month", date_labels = "%b%Y") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Shooting Incidents by Time of Day

After exploring the shootings over time, I decided I wanted to focus the rest of this project specifically around time. I wanted to create a visual plotting the time of day where shooting incidents occured. My hypothesis was that the plots would create a U shape with the X axis series of the 24 hours of a day. I infered that shooting incidents were higher during the dark hours of each day, and lower during the light hours. As you can see, the general pattern with the plots follows exactly that prediction. From 12am-7am, the occurences started high and declined as it got later into the early morning. During the morning until the afternoon, the incident rate stayed relatively low. As afternoon progressed into evening and then night, the incidents began to rise again.

``` {r time of day}
#create field for time
cleaned_data$Time <- format(cleaned_data$OCCUR_DATETIME, "%H:%M:%S")

#group the incidents by time of day
time_of_day <- cleaned_data %>%
  group_by(Time) %>%
  summarise(Incident_Count = n())

# Ensure Time is in the correct format
time_of_day$Time <- as.POSIXct(time_of_day$Time, format = "%H:%M:%S")

#plot shooting incidents by time of day
ggplot(time_of_day, aes(x = Time, y = Incident_Count)) +
  geom_point(color = "darkorange", size = 1) +
  labs(title = "Shooting Incidents by Time of Day",
       x = "Time of Day",
       y = "Number of Incidents") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_datetime(date_labels = "%H:%M", 
                   breaks = scales::breaks_width("1 hour"))

```

## Model on Relationship Between Incidents by Time of Day and Borough

Using all aspects of my analysis so far, I wanted to explore the relationship between the time of day and neighborhood for shooting incidents that occurred. I also wanted to model out a prediction, based on the data, of how many crimes may occur going forward based on the neighborhood and time of day. I researched different ways I could achieve this, and chose a Poisson regression model. As a result, the model suggest there are several significant predictors indicating that time of day and borough are important factors when predicting shooting counts that may occur. This could be used in many ways. For the public, it is useful for taking extra safetly measures when visiting certain areas during specific times of the day. For law enforcement, this is good information for policing strategies and allocation of officers in specific neighborhoods at different times of the day. 

``` {r model}
#Extract hour from OCCUR_DATETIME
cleaned_data <- cleaned_data %>%
  mutate(HOUR = format(OCCUR_DATETIME, "%H"))

#Aggregate data by hour and borough
shooting_summary <- cleaned_data %>%
  group_by(BORO, HOUR) %>%
  summarise(SHOOTING_COUNT = n(), .groups = 'drop')


#Based on my research, I wanted to use a Poisson regression model to predict 
#crime counts versus actual
model <- glm(SHOOTING_COUNT ~ HOUR + BORO, data = shooting_summary, 
             family = "poisson")
summary(model)
shooting_summary$predicted_counts <- predict(model, type = "response")

#Create a graph to show the actual versus predicted shootings by time of day by 
#neighborhood
shooting_graph <- shooting_summary %>%
  pivot_longer(cols = c(SHOOTING_COUNT, predicted_counts), 
               names_to = "Type", 
               values_to = "Count")
ggplot(shooting_graph, aes(x = HOUR, y = Count, color = BORO, 
                           group = interaction(BORO, Type))) +
  geom_line(aes(linetype = Type), size = 1) +
  geom_point() +
  labs(title = "Actual vs. Predicted Shooting Counts by Hour and Borough",
       x = "Hour of the Day",
       y = "Number of Crimes") +
  theme_minimal() +
  scale_linetype_manual(values = c("solid", "dashed")) +
  theme(legend.title = element_blank())
```

## Conclusion

Overall, there were many interesting ways I could have explored this dataset. During my exploration, I was initially most interested in the significance of time and location of where these shootings were occuring. I had limited bias when exploring this dataset since I am generally unfamiliar with New York City, but there was some. I expected to see higher crime in Manhattan especially because that is where shootings and other major crimes occur in New York City that often make national headlines as I recollect. I also had a bias regarding Brooklyn since my sister lives there, creating a personal connection. To mitigate this bias, I took the approach that all areas have their safe and not as safe areas that create hot spots for overall statistics which is why a deeper analysis could be done using the coordinate data. In the future, I may build a Shiny app and do a spatial analysis to dig deeper into specific areas of specific neighborhoods. For the time of day, I was happy to see both the actual and predictive lines on the graph line up with what I was expecting. This analysis has likely been done by data scientists for the city of New York, but is definitely important information for both the public and law enforcement. It would be very interesting to explore other correlations outside this dataset such as other crime statistics such as illegal drug use to explore any significance. 

